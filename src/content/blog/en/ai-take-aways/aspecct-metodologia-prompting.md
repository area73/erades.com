---
title: "Methodologies: How to ask the AI"
description: "Practical guide for writing effective prompts using the ASPECCT methodology, with template, real example and comparison with alternative frameworks."
pubDate: 2025-08-10
tags:
  - ASPECCT
  - prompt-engineering
  - best-practices
  - artificial-intelligence
categories:
  - AI
  - Crafting
draft: false
heroImage: /blog-placeholder-21.jpg
---

The quality of a model's responses depends largely on the quality of the prompt. **ASPECCT** is a simple and powerful way to structure what you ask for to achieve consistent results.

## What is ASPECCT

- **A — Audience**: defines who the output is for.
- **S — Style**: tone and register (technical, mentor, formal…).
- **P — Purpose**: clear goal of the task.
- **E — Examples**: reference inputs/outputs.
- **C — Constraints**: word limits, format, prohibitions.
- **Cxt — Context**: what the model should know about the domain/situation.
- **T — Type of Output**: expected format (list, table, JSON, Markdown).

## One to give an example

Final Prompt:

> "Write a short list (T) that explains the benefits of serverless (P) to startup CTOs (A) using a concise and technical tone (S). It should be less than 80 words and use bullets (C). Context: we are preparing internal documentation for developers inexperienced with AWS (Cxt)."

## Is the ASPECCT methodology good?

ASPECCT encapsulates prompting principles widely recommended by the industry: **provide clear and specific instructions, provide context, show examples, and set an output format**.

These practices are aligned with the official guides of the companies that generate models:

- **OpenAI:** prompting guides and best practices (clear instructions, break down tasks, provide examples, and output format).
- **Anthropic:** prompting strategies (role/persona, constraints, context, format, and step-by-step reasoning when appropriate).
- **Google (Gemini):** prompt design with objectives, context, examples, and response format.

There is independent evidence that a single framework outperforms others in all cases; **ASPECCT is robust** because it covers the elements that most influence the quality of the response and is easy to apply consistently.

## Other alternatives

As in everything, and especially when we are at the beginning of this new age, there are other very valid alternatives.

- **CO-STAR** (Context, Objective, Style, Tone, Audience, Response): functionally equivalent to ASPECCT with explicit emphasis on tone and response style. Useful when **branding/voice** is crucial.

- **CRISPE**: popular variants focus on constraints, role/persona, user inputs, steps, and examples. Useful for **repeatable operational tasks with strict checklist**.

- **Best practice from provider** (OpenAI, Anthropic, Google): they combine the same principles with tactical recommendations (e.g., breaking down problems, using examples, asking for a structured format).

- In reasoning problems, it is recommended to add techniques such as "step-by-step reasoning" or "decomposition into subtasks".

- In structured outputs, specify the schema and validation (e.g., strictly typed JSON).

## An approach to creating the prompt

1. Complete the ASPECCT checklist before writing the prompt.
2. Write a first draft.
3. Ask for the result in the exact format (Type of Output) and within boundaries (Constraints).
4. Iterate with 1–2 examples (Examples) if the output does not comply.
5. Reinforce purpose, audience, and style if you notice drift.

<div class="bibliography">

## Bibliography and references

- OpenAI — Best practices for prompt engineering: [platform.openai.com/docs/guides/prompt-engineering](https://platform.openai.com/docs/guides/prompt-engineering)
- Anthropic — Prompt engineering overview (Claude): [docs.anthropic.com/.../prompt-engineering/overview](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)
- Google — Writing effective prompts (Workspace/Gemini): [workspace.google.com/resources/ai/writing-effective-prompts](https://workspace.google.com/resources/ai/writing-effective-prompts)
- Microsoft Learn — Prompt engineering (Azure OpenAI): [learn.microsoft.com/.../prompt-engineering](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering)
- Prompt Engineering Guide (DAIR.AI): [promptingguide.ai](https://www.promptingguide.ai/)
- CO-STAR Framework (introduction and practical examples): [writesonic.com/blog/costar-framework](https://writesonic.com/blog/costar-framework)

</div>
